import os
import json
import time
import pandas as pd
import sys
from dotenv import load_dotenv
from google import  genai 

# === è¨­å®š ===
csv_file_path = "japanese_pretest.csv"
jlpt_file_path = "japanese_learning_info.csv"
chunk_size = 1000
batch_size = 12
output_csv = "2output.csv"
delimiter = "-----"

ITEMS = [
]

# === è¼‰å…¥ API Key ===
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")


# === JSON Parse Function ===
def parse_response(response_text):
    cleaned = response_text.strip()
    if cleaned.startswith("```"):
        lines = cleaned.splitlines()
        if lines[0].startswith("```"):
            lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        cleaned = "\n".join(lines).strip()

    try:
        result = json.loads(cleaned)
        for item in ITEMS:
            if item not in result:
                result[item] = ""
        return result
    except Exception as e:
        print(f"âš ï¸ è§£æ JSON å¤±æ•—ï¼š{e}")
        print("åŸå§‹å›å‚³å…§å®¹ï¼š", response_text)
        return {item: "" for item in ITEMS}

# === Dialogue Column Detection ===
def select_dialogue_column(chunk: pd.DataFrame) -> str:
    preferred = ["text", "utterance", "content", "dialogue", "Dialogue"]
    for col in preferred:
        if col in chunk.columns:
            return col
    print("âš ï¸ æ‰¾ä¸åˆ°é è¨­æ¬„ä½ï¼Œå°‡ä½¿ç”¨ç¬¬ä¸€å€‹æ¬„ä½ï¼š", list(chunk.columns))
    return chunk.columns[0]

# === Classify by Score ===
def classify_level(score):
    if score < 45:
        return "Beginner"
    elif 45 <= score < 55:
        return "Intermediate"
    else:
        return "Advanced"

# === å°‡å­¸ç”Ÿåˆ†ç´šä¸¦è¼¸å‡ºåˆ†é¡çµæœ ===
def classify_and_export():
    pretest_df = pd.read_csv(csv_file_path)
    jlpt_df = pd.read_csv(jlpt_file_path)
    merged_df = pd.merge(pretest_df, jlpt_df, on="StudentID")
    merged_df["Class_Level"] = merged_df["Total_Score"].apply(classify_level)

    class_groups = {
        "Beginner": merged_df[merged_df["Class_Level"] == "Beginner"],
        "Intermediate": merged_df[merged_df["Class_Level"] == "Intermediate"],
        "Advanced": merged_df[merged_df["Class_Level"] == "Advanced"]
    }

    for level, df in class_groups.items():
        filename = f"class_{level.lower()}.csv"
        df.to_csv(filename, index=False)

    return merged_df

# === æ‰¹æ¬¡åˆ†æé€å­—ç¨¿ ===
def process_batch_dialogue(client, dialogues: list):
    prompt = (
        "ä½ æ˜¯ä¸€ä½æ—¥æ–‡æ•™å­¸å°ˆå®¶ï¼Œè«‹æ ¹æ“šä»¥ä¸‹ç·¨ç¢¼è¦å‰‡è©•ä¼°æ˜¯å¦èˆ‡æ—¥èªæ•™å­¸çš„ç›®æ¨™ç›¸åŒï¼š\n"
        + "\n".join(ITEMS) +
        "\n\nè«‹ä¾æ“šè©•ä¼°çµæœï¼Œå°æ¯å€‹é …ç›®ï¼šè‹¥è§¸åŠå‰‡æ¨™è¨˜ç‚º Yesï¼Œå¦å‰‡æ¨™è¨˜ç‚º Noã€‚"
        "è«‹å°æ¯ç­†é€å­—ç¨¿ç”¢ç”Ÿ JSON æ ¼å¼å›è¦†ï¼Œä¸¦åœ¨å„ç­†çµæœé–“ç”¨ä¸‹åˆ—åˆ†éš”ç·šéš”é–‹ï¼š\n"
        f"{delimiter}\n"
        "ä¾‹å¦‚ï¼š\n"
        "```json\n"
        "{ \"Vocab\": \"Yes\", \"Listening\": \"No\", ... }\n"
        f"{delimiter}\n"
        "{...}\n```"
    )

    batch_text = f"\n{delimiter}\n".join(dialogues)
    content = prompt + "\n\n" + batch_text

    try:
        response = client.generate_content(
            model="models/gemini-1.5-flash-latest",
            contents=[{"role": "user", "parts": [content]}]
        )
    except Exception as e:
        print(f"âŒ API å‘¼å«å¤±æ•—ï¼š{e}")
        return [{item: "" for item in ITEMS} for _ in dialogues]

    response_text = response.text if hasattr(response, "text") else response.candidates[0].content.parts[0].text
    print("âœ… æ‰¹æ¬¡ API å›å‚³å…§å®¹ï¼š", response_text)

    parts = response_text.split(delimiter)
    results = []
    for part in parts:
        part = part.strip()
        if part:
            results.append(parse_response(part))

    while len(results) < len(dialogues):
        results.append({item: "" for item in ITEMS})
    return results[:len(dialogues)]

# === ä¸»ç¨‹å¼ ===
def main():
    if len(sys.argv) < 2:
        print("ğŸ“Œ ä½¿ç”¨æ–¹å¼ï¼špython3 second.py")
        sys.exit(1)

    input_csv = sys.argv[1]
    if os.path.exists(output_csv):
        os.remove(output_csv)

    df = pd.read_csv(input_csv)
    dialogue_col = select_dialogue_column(df)
    print(f"ğŸ” ä½¿ç”¨æ¬„ä½ä½œç‚ºé€å­—ç¨¿ä¾†æºï¼š{dialogue_col}")

    total = len(df)
    for start_idx in range(0, total, batch_size):
        end_idx = min(start_idx + batch_size, total)
        batch = df.iloc[start_idx:end_idx]
        dialogues = [str(d).strip() for d in batch[dialogue_col]]
        batch_results = process_batch_dialogue(genai, dialogues)

        batch_df = batch.copy()
        for item in ITEMS:
            batch_df[item] = [res.get(item, "") for res in batch_results]

        mode = 'w' if start_idx == 0 else 'a'
        header = (start_idx == 0)
        batch_df.to_csv(output_csv, mode=mode, index=False, header=header, encoding="utf-8-sig")
        print(f"âœ… å·²è™•ç† {end_idx}/{total} ç­†è³‡æ–™")

        time.sleep(1)

    print(f"ğŸ‰ å…¨éƒ¨è™•ç†å®Œæˆã€‚å·²å„²å­˜æ–¼ï¼š{output_csv}")

if __name__ == "__main__":
    classify_and_export()
    main()
    